{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 01:01:33.415784: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 01:01:33.971866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9617 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from aesindy.__init__ import *\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle5 import pickle\n",
    "from os import listdir\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from aesindy.analyze import get_names, read_results, delete_results, get_cases, params_names, load_results\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jbakarji/Documents/codes/deep-delay-autoencoder'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOTPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print available cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lorenzww_basic\n",
      "fluttering_basic\n",
      "pendulum_basic\n",
      "fluttering_Re1000\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(ROOTPATH,'testcases/results/')\n",
    "cases = get_cases(path, filter_case=None, print_cases=True)\n",
    "p1, p2, p3 = params_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get names for a given case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 results_202211250041_pendulum_basic\n",
      "1 results_202211230237_pendulum_basic\n",
      "2 results_202209011328_fluttering_Re1000\n",
      "3 results_202208311839_pendulum_basic\n",
      "4 results_202208311838_pendulum_basic\n",
      "5 results_202208311834_pendulum_basic\n",
      "6 results_202208311831_fluttering_Re1000\n",
      "7 results_202208300802_fluttering_Re1000\n",
      "8 results_202208300729_fluttering_Re1000\n",
      "9 results_202208292212_fluttering_Re1000\n",
      "10 results_202208292145_fluttering_Re1000\n",
      "11 results_202208292052_fluttering_Re1000\n",
      "12 results_202208291949_fluttering_Re1000\n",
      "13 results_202208291942_fluttering_basic\n",
      "14 results_202208291941_fluttering_basic\n",
      "15 results_202208291910_lorenzww_basic\n",
      "16 results_202208291909_lorenzww_basic\n",
      "17 results_202208291902_lorenzww_basic\n",
      "18 results_202208291834_lorenzww_basic\n",
      "19 results_202208291754_lorenzww_basic\n",
      "20 results_202208291327_pendulum_basic\n",
      "21 results_202208291325_pendulum_basic\n",
      "22 results_202208291322_pendulum_basic\n",
      "23 results_202208180322_pendulum_basic\n",
      "24 results_202208180308_pendulum_basic\n"
     ]
    }
   ],
   "source": [
    "name_list = get_names(cases, path)\n",
    "for idx, name in enumerate(name_list): print(idx, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  results_202211230237_pendulum_basic\n"
     ]
    }
   ],
   "source": [
    "end_time = 30\n",
    "end_time_plot = 100\n",
    "display_params = p1 #primary_params + secondary_params + tertiary_params\n",
    "t0_frac = 0.2\n",
    "query_remove = True\n",
    "\n",
    "non_existing_files, non_existing_params, remove_files = read_results([name_list[1]], \n",
    "                                                        path, \n",
    "                                                        end_time=end_time, \n",
    "                                                        display_params=display_params, \n",
    "                                                        t0_frac=t0_frac, \n",
    "                                                        end_time_plot=end_time_plot,\n",
    "                                                        query_remove=query_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 01:01:53.872330: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(path+name_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_existing_params\n",
    "# delete_results(non_existing_files, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "28edffddebd8e7e82695004644e928e55a1390a00736088cc396dbbdc4e98ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
